# Lab 05 - Czyszczenie danych

Celem czyszczenia danych jest:
- wykrycie elementÃ³w brakujÄ…cych i ich uzupeÅ‚nienie lub usuniÄ™cie wierszy
- konwersja danych (np daty) i typÃ³w nominalnych (w tym korekta bÅ‚Ä™dÃ³w w nazwach elementÃ³w, np. poznaÅ„, Poznan, Pznan, PoznaÅ„)
- analiza rozkÅ‚adÃ³w i usuniÄ™cie elementÃ³w odstajÄ…cych (outlierÃ³w) (Lab 06)
- normalizacja danych i normalizacja rozkÅ‚adu (Lab 06)

### ZbiÃ³r danych

W zadaniach bÄ™dziemy posÅ‚ugiwaÄ‡ siÄ™ zbiorem opisujÄ…cym historiÄ™ sprzedaÅ¼y budynkÃ³w, zawierajÄ…cym szczegÃ³Å‚y dotyczÄ…ce nieruchomoÅ›ci oraz cenÄ™ za jakÄ… zostaÅ‚y sprzedane: [melb_data.csv](./_resources/lab_05/melb_data.csv).

### Ocena efektÃ³w - skutecznoÅ›Ä‡ klasyfikacji

W zadaniach sprÃ³buj odnieÅ›Ä‡ efekty wprowadzonych zmian do efektu dla zadania klasyfikacji. Do oceny zastosuj funkcjÄ™:

```python
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error


def score_dataset(x_train, x_valid, y_train, y_valid):
    model = RandomForestRegressor(n_estimators=100, random_state=0)
    model.fit(x_train, y_train)
    preds = model.predict(x_valid)
    return mean_absolute_error(y_valid, preds)
```

Do oceny skutecznoÅ›ci klasyfikacji stosuj zawsze zbiÃ³r uczÄ…cy i testowy, tzn. wszelkie hipotezy, wyznaczanie statystyk (np. wartoÅ›ci Å›redniej, kwartyli) wyznaczaj wyÅ‚Ä…cznie dla zbioru uczÄ…cego, a nastÄ™pnie metodÄ™ zastosuj dla zbioru testowego (bez zmiany wartoÅ›ci wyznaczonych parametrÃ³w). PodziaÅ‚ na zbiÃ³r uczÄ…cy i testowego przeprowadÅº w proporcji 70/30%. PodziaÅ‚ na zbiory przeprowadÅº na poczÄ…tku i potem uÅ¼ywaj tych zbiorÃ³w dla wszystkich danych (rozwiÄ…zanie to zawiera pewien bÅ‚Ä…d metodyczny wynikajÄ…cy z wielokrotnego wykorzystania tego samego zbioru, zajmiemy siÄ™ tym na Lab 07).

```python
from sklearn.datasets import make_blobs
from sklearn.model_selection import train_test_split


train_df, test_df = train_test_split(df, test_size=0.7)
# czyszczenie danych
# train_df_cleaned = ...
# test_df_cleaned = ...

cols_x = train_df_cleaned.select_dtypes(include=[np.number]).columns.difference(['Price'])  # wybiera tylko kolumny z wartosciami numerycznymi, za wyjÄ…tkiem kolumny z wartoÅ›ciÄ… referencyjnÄ… - wejÅ›cie do klasyfikatora
cols_y = 'Price'  # - wyjÅ›cie z klasyfikatora
print(score_dataset(train_df_cleaned[cols_x], test_df_cleaned[cols_x], train_df_cleaned[cols_y], test_df_cleaned[cols_y]))
```

**UWAGA** 
1. Funkcja `score_dataset` zwraca Å›redniÄ… z wartoÅ›ci bezwzglÄ™dnej bÅ‚Ä™du dla zbioru testowego. 
2. Do oceny skutecznoÅ›ci stosujemy zbiÃ³r testowy, ktÃ³ry nie zostaÅ‚ uÅ¼yty w procedurze uczenia i wyboru metody.
3. PamiÄ™taj jednak, Å¼e jednoznaczna interpretacja tego czy rÃ³Å¼nica miÄ™dzy oboma podejÅ›ciami jest istotna statystycznie wymaga rozszerzonej analizy, zajmiemy siÄ™ tym na Lab 07.
4. PorÃ³wnujÄ…c otrzymany wynik bÅ‚Ä™du sprÃ³buj okreÅ›liÄ‡ dlaczego nastÄ…piÅ‚a zmiana, pamiÄ™taj przy tym, Å¼e podejÅ›cie zwiÄ…zane z czyszczeniem danych zaleÅ¼y od typu danych.  

## Elementy brakujÄ…ce

1. Wczytaj zbiÃ³r danych z [pliku](./_resources/lab_05/melb_data.csv) do zmiennej `df`
2. Wyznacz liczbÄ™ wartoÅ›ci brakujÄ…cych (pustych) i przeanalizuj w jakich kolumnach wystÄ™pujÄ… braki

```python
missing_values_count = df.isnull().sum()
```
- SprÃ³buj okreÅ›liÄ‡ dla kaÅ¼dej kolumny procent wystÄ™powania wartoÅ›ci brakujÄ…cych. WyÅ›wietl je w postaci tabeli, gdzie indeksem jest nazwa kolumny, a kolumnami procent brakÃ³w oraz caÅ‚kowita liczba brakÃ³w (moÅ¼esz uÅ¼yÄ‡ metody `pd.concat`)

### PodejÅ›cie 1: usuniÄ™cie kolumn/wierszy zawierajÄ…cych przynajmniej 1 element pusty - przetestuj oba podejÅ›cia:

```Python
df_cleaned_rows = df_set.dropna()
df_cleaned_cols = df_set.dropna(axis=1)
```
- ZastanÃ³w siÄ™, ktÃ³re z tych podejÅ›Ä‡ powinno byÄ‡ zastosowane jeÅ›li chcemy stworzyÄ‡ klasyfikator predykujÄ…cy ceny nieruchomoÅ›ci?
- Czy wiesz, ktÃ³re wiersze zostaÅ‚y usuniÄ™te? SprÃ³buj wyodrÄ™bniÄ‡ listÄ™ ich indeksÃ³w.
- SprawdÅº dokumentacjÄ™ [dropna](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html) i zobacz:
  -  w jaki sposÃ³b usunÄ…Ä‡ tylko wiersze z jeÅ›li wartoÅ›ci puste sÄ… w kolumnie `BuildingArea`, 
  -  ograniczajÄ…c liczbÄ™ wierszy sprawdÅº ile zostanie wierszy jeÅ›li usunie siÄ™ wiersze, ktÃ³re nie majÄ… **rÃ³wnoczeÅ›nie** wypeÅ‚nionego pola `BuildingArea` i  `YearBuilt`
  
### PodejÅ›cie 2: wypeÅ‚nienie pustych wartoÅ›ci np. zerami lub wartoÅ›ciÄ…, ktÃ³ra poprzedza wartoÅ›Ä‡ brakujÄ…cÄ…

```python
df_cleaned_zeros = df.fillna(0) # wypeÅ‚nia zerami
df_cleaned_bfill = df.fillna(method='bfill', axis=0).fillna(0)  # wypeÅ‚nia wartoÅ›ciÄ… poprzedzajÄ…cÄ… z danej kolumny, jeÅ›li to niemoÅ¼liwe, wstawia 0
```

- ZastanÃ³w siÄ™ kiedy takie podejÅ›cie moÅ¼e byÄ‡ stosowane, czy moÅ¼na je uÅ¼yÄ‡ do klasyfikacji?, sprawdÅº w dokumentacji [fillna](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html) jakie sÄ… jeszcze moÅ¼liwoÅ›ci wypeÅ‚nienia wypeÅ‚nienia?
- Kiedy wypeÅ‚nianie wartoÅ›ciÄ… sÄ…siedniÄ… ma sens? JeÅ›li stosujemy je do klasyfikacji to jakÄ… strategiÄ™ przyjÄ…Ä‡ w odniesieniu do brakujÄ…cych wartoÅ›ci referencyjnych (jest to wartoÅ›Ä‡, ktÃ³ra ma byÄ‡ predykowana przez klasyfikator) a jakÄ… w odniesieniu do brakujÄ…cych cech (wartoÅ›Ä‡/wartoÅ›ci, ktÃ³re sÄ… wejÅ›ciem klasyfikatora)?

### PodejÅ›cie 3: podstawienie wartoÅ›ci Å›redniej/mediany/mody:

```python
from sklearn.impute import SimpleImputer


imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean') 
df_train_numeric = train_df.select_dtypes(include=[np.number]).copy()
df_test_numeric = test_df.select_dtypes(include=[np.number]).copy()#wybÃ³r tylko kolumn przechowujacych liczby, naleÅ¼y wykonaÄ‡ kopiÄ™ obiektu

df_train_numeric.loc[:] = imp_mean.fit_transform(df_train_numeric)  # dopasowanie parametrÃ³w (Å›rednich) i transformacja zbioru uczÄ…cego
df_test_numeric[:]  = imp_mean.transform(df_test_numeric)  # zastosowanie modelu do transformacji zbioru testowego (bez wyznaczania parametrÃ³w)
```
- Kiedy wypeÅ‚nianie wartoÅ›ciÄ… Å›redniÄ…/medianÄ… ma sens? JeÅ›li stosujemy je do klasyfikacji to jakÄ… strategiÄ™ przyjÄ…Ä‡ w odniesieniu do brakujÄ…cych wartoÅ›ci referencyjnych (jest to wartoÅ›Ä‡, ktÃ³ra ma byÄ‡ predykowana przez klasyfikator) a jakÄ… w odniesieniu do brakujÄ…cych cech (wartoÅ›Ä‡/wartoÅ›ci, ktÃ³re sÄ… wejÅ›ciem klasyfikatora)?
- OceÅ„ skutecznoÅ›Ä‡ klasyfikacji i porÃ³wnaj jÄ… z pozostaÅ‚ymi podejÅ›ciami

## Konwersja danych

### Daty i czasy

#### Konwersja dat i czasÃ³w

Dane bardzo czÄ™sto zwiÄ…zane sÄ… z datÄ…/czasem wystÄ…pienia, rejestracji itp. PrzykÅ‚adowo, uÅ¼ywany zbiÃ³r danych w kolumnie `Date` przechowuje datÄ™ sprzedaÅ¼y. PoniewaÅ¼ zawiera ona znaki inne niÅ¼ cyfry/punkt dziesiÄ™tny zaczytywana jest domyÅ›lnie z pliku CSV jako string:

```python
print(type(df.loc[0, "Date"]))
```

W celu dalszego wygodnego wykorzystania takie dane wymagajÄ… konwersji na format zrozumiaÅ‚y dla wykorzystywanych narzÄ™dzi. W Pandas mamy do dyspozycji funkcjÄ™ `to_datetime()` pozwalajÄ…cÄ… na utworzenie serii/indeksu typu `Datetime` na podstawie ÅºrÃ³dÅ‚owych liczb, napisÃ³w etc:

```python
df.loc[:, "Datetime"] = pd.to_datetime(df.loc[:, "Date"])
```

MnogoÅ›Ä‡ formatÃ³w zapisu dat i czasÃ³w (np. DD-MM-YYYY lub MM-DD-YYYY) powoduje jednak, Å¼e funkcja `to_datetime` moÅ¼e niepoprawnie odgadnÄ…Ä‡ format wejÅ›ciowy. PorÃ³wnaj uzyskane kolumny `Date` i `Datetime` - czy dane wejÅ›ciowe byÅ‚y zawsze interpretowane tak samo?

Funkcja `to_datetime` ma wiele dodatkowych opcji: [to_datetime](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_datetime.html). SprÃ³buj za pommocÄ… parametru `format=` wymusiÄ‡ poprawny format ÅºrÃ³dÅ‚owy daty. 

#### Wyznaczanie zakresÃ³w dat i interwaÅ‚Ã³w

SeriÄ™ dat z okreÅ›lonym poczÄ…tkiem, koÅ„cem i okresem moÅ¼na wygenerowaÄ‡ funkcjÄ… `date_range`: [dokumentacja](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.date_range.html)

Zakres (interwaÅ‚) dat, ktÃ³ry moÅ¼e sÅ‚uÅ¼yÄ‡ do wyÅ‚uskania fragmentu tabeli moÅ¼na wygenerowaÄ‡ funkcjÄ… `Interval`, podajÄ…c jako granice `Timestamp`:

PrzykÅ‚adowo:

```python
year_2017 = pd.Interval(pd.Timestamp('2017-01-01 00:00:00'), pd.Timestamp('2018-01-01 00:00:00'), closed='left')
```

#### Wyznaczanie dnia tygodnia

Pewne cechy wykazujÄ… zmiennoÅ›Ä‡ nie wprost od upÅ‚ywu czasu (monotonicznie), co np. od dnia tygodnia, dnia miesiÄ…ca itp. DysponujÄ…c datÄ…/czasem w formacie datetime Å‚atwo skonwertujemy jÄ… na dzieÅ„ tygodnia w formacie liczbowym od 0 (poniedziaÅ‚ek) do 6 (niedziela) przy pomocy pola `DataFrame.dt.dayofweek`.

```python
df.loc[:, "Day of week"] = df.loc[:, "Datetime"].dt.dayofweek
```

#### ğŸ”¥ Zadanie ğŸ”¥

WykreÅ›l histogram liczby dokonanych transakcji w zaleÅ¼noÅ›ci od dnia tygodnia.

### Zmienne nominalne

Zmienne nominalne (*categorical data*) to takie, ktÃ³re przyjmujÄ… wartoÅ›ci z okreÅ›lonego, skoÅ„czonego zbioru, dla ktÃ³rych nie istnieje Å¼adne domyÅ›lne uporzÄ…dkowanie (np. miasto urodzenia, pÅ‚eÄ‡). W przypadku programowania moÅ¼na posÅ‚uÅ¼yÄ‡ siÄ™ analogiÄ… do typÃ³w wyliczeniowych (np. `enum` z `C++`). Zazwyczaj kategorii bÄ™dzie znacznie mniej niÅ¼ prÃ³bek danych.

#### Konwersja na zmiennÄ… nominalnÄ…

Dane typu *categorical* moÅ¼emy wygenerowaÄ‡ na kilka sposobÃ³w, np rÄ™cznie, wymuszajÄ…c typ danych `category` parametrem `dtype`:

```python
categorical_series = pd.Series(["a", "b", "c", "a"], dtype="category")
print(categorical_series)
```

lub konwertujÄ…c istniejÄ…cÄ… kolumnÄ™ DataFrame:

```python
df["B"] = df["A"].astype("category")
```

Dla omawianej bazy sprzedaÅ¼y nieruchomoÅ›ci moÅ¼emy przykÅ‚adowo skonwertowaÄ‡ kolumnÄ™ `RegionName`:

```python
df.loc[:, "RegionName"] = df.loc[:, "RegionName"].astype("category")
print(df["Regionname"])
```

#### ÅÄ…czenie zmiennych nominalnych (usuwanie literÃ³wek) przy pomocy `fuzzywuzzy`

W przypadku rÄ™cznego wprowadzania danych np. przez osoby ankietowane lub przez rÃ³Å¼ne instytucje, dane nominalne rÃ³Å¼niÄ… siÄ™ wielkoÅ›ciÄ… liter, sposobem zapisu (ze znakami diakrytycznymi lub bez) lub zawierajÄ… literÃ³wki. W przypadku nazw miejsc nazwy mogÄ… posiadaÄ‡ lub nie dodatkowe czÅ‚ony (np. OstrÃ³w i OstrÃ³w Wlkp i Ostrow Wielkoposlki, jak rÃ³wnieÅ¼ ostrow wlkp). Wszystkie takie wpisy powinny trafiÄ‡ do jednej kategorii.

W przypadku zmiany rÃ³Å¼nicy w wielkoÅ›ci liter moÅ¼liwe jest konwersja wszystkich elementÃ³w w kolumnie na np. maÅ‚e litery oraz usuniÄ™cie znakÃ³w spacji. SprawdÅº (uÅ¼ywajÄ…c `np.unique(...)`) ile rÃ³Å¼nych unikalnych elementÃ³w w kolumnie `Suburb`? PorÃ³wnaj ten wynik z wynikiem otrzymanym po znormalizowaniu wielkoÅ›ci liter oraz usuniÄ™ciu koÅ„cowych znakÃ³w spacji

```python
# zmiana na maÅ‚e litery
df['Suburb'] = df['Suburb'].str.lower()
# usuniÄ™cie koÅ„cowych spacji
df['Suburb'] = df['Suburb'].str.strip()
```

W danych mogÄ… siÄ™ jednak znajdowaÄ‡ takie same elementy rÃ³Å¼niÄ…ce siÄ™ literÄ… (literÃ³wka) lub posiadajÄ…ce dodatkowe czÅ‚ony w nazwie. Do porÃ³wnania dwÃ³ch napisÃ³w, lub napisu z listÄ… innych napisÃ³w moÅ¼na uÅ¼yÄ‡ moduÅ‚ `fuzzywuzzy`

```python
import fuzzywuzzy.process


fuzzywuzzy.process.extract('OstrÃ³w',['ostrow', 'OstrÃ³w Wlkp', 'ostrÃ³w wlkp', 'OstrzeszÃ³w'])
```

Funkcja zwrÃ³ci listÄ™ krotek, gdzie drugi element okreÅ›la podobieÅ„stwo.
Do scalenia pewnego ciÄ…gu znakÃ³w z elementami kolumny pandas, moÅ¼e sÅ‚uÅ¼yÄ‡ funkcja:

```python
import fuzzywuzzy.process


def replace_matches_in_column(df, column, string_to_match, min_ratio = 90):
    # get a list of unique strings
    strings = df[column].unique()
    
    # get the top 10 closest matches to our input string
    matches = fuzzywuzzy.process.extract(string_to_match, strings, 
                                         limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio)

    # only get matches with a ratio > 90
    close_matches = [matches[0] for matches in matches if matches[1] >= min_ratio]

    # get the rows of all the close matches in our dataframe
    rows_with_matches = df[column].isin(close_matches)

    # replace all rows with close matches with the input matches 
    df.loc[rows_with_matches, column] = string_to_match
```

#### ğŸ”¥ Zadanie ğŸ”¥

PodmieÅ„ wczytywany plik na [melb_data_distorted.csv](./_resources/lab_05/melb_data_distorted.csv), w ktÃ³rym w niektÃ³rych kolumnach tekstowych zostaÅ‚y wprowadzone typowe pomyÅ‚ki lub rÃ³Å¼nice w zapisie.

SprÃ³buj zastosowaÄ‡ funkcjÄ™ `replace_matches_in_column` do scalenia elementÃ³w w kolumnie `Suburb`, pamiÄ™taj, Å¼e trzeba jÄ… wywoÅ‚aÄ‡ osobno dla kaÅ¼dego unikalnego elementu `string_to_match`. Ile unikalnych elementÃ³w zostanie, jeÅ›li minimalny prÃ³g podobieÅ„stwa ustalisz na wartoÅ›Ä‡ 90?
  
#### Konwersja *zmienna porzÄ…dkowa* â†’ *wartoÅ›ci liczbowe*

Wykorzystanie zmiennych jako wejÅ›cia w systemach klasyfikacji/regresji wymaga podania wartoÅ›ci liczbowej. Jednym z podejÅ›Ä‡, ktÃ³re moÅ¼na zastosowaÄ‡ jest przypisanie poszczegÃ³lnym wartoÅ›ciom zmiennej nominalnej specyficznej wartoÅ›ci (np. 1, 2, 3, ...)

```python
from sklearn.preprocessing import LabelEncoder


# Make copy to avoid changing original data 
label_train = train_df.copy()
label_test = test_df.copy()

# Apply label encoder to each column with categorical data
label_encoder = LabelEncoder()
col='CouncilArea'
label_train[col] = label_encoder.fit_transform(label_train[col])
label_test[col] = label_encoder.transform(label_test[col])
```

- â“ZastanÃ³w siÄ™ czy podejÅ›cie to sprawdzi siÄ™ w celu uwzglÄ™dnienia w predyktorze ceny nazw obszarÃ³w administracyjnych, lub dni tygodnia w ktÃ³rych nastÄ…piÅ‚a sprzedaÅ¼?
- â“ZastanÃ³w siÄ™ czy podejÅ›cie takie sprawdzi siÄ™ do klasyfikacji zmiennej nominalnej *siÅ‚a wiatru*, gdzie zbiorem wartoÅ›ci jest [*brak*, *sÅ‚aby*, *silny*, *bardzo silny*]?
  
#### Zmienna nominalna â†’ enkoder binarny

Innym moÅ¼liwym podejÅ›ciem jest konwersja zmiennej nominalnej o `n` wartoÅ›ciach na `n` kolumn, z ktÃ³rych kaÅ¼da okreÅ›la wartoÅ›ciÄ… 0 lub 1 to czy dana wartoÅ›Ä‡ wystÄ…piÅ‚a. Procedura ta nazwya siÄ™ rÃ³wnieÅ¼ *one-hot encoder*. PorÃ³wnanie sposobu transformacji za pomocÄ… `LabelEncodera` i `LabelBinarizer`/(poÅ‚Ä…czenia `LabelEncoder` i `OneHotEncoder`) przedstawiono na rysunku:

[encoders](./_images/lab_04/encoders.jpg)

```python
from sklearn.preprocessing import LabelBinarizer


# Make copy to avoid changing original data 
label_train = train_df.copy()
label_test = test_df.copy()

label_binarizer = LabelBinarizer()

col = 'CouncilArea'
lb_results = label_binarizer.fit_transform(label_train[col])
lb_results_df = pd.DataFrame(lb_results, columns=label_binarizer.classes_)
```
- â“ZastanÃ³w siÄ™ czy podejÅ›cie to sprawdzi siÄ™ w celu uwzglÄ™dnienia w predyktorze ceny nazw obszarÃ³w administracyjnych, lub dni tygodnia w ktÃ³rych nastÄ…piÅ‚a sprzedaÅ¼?
- â“ZastanÃ³w siÄ™ czy podejÅ›cie takie sprawdzi siÄ™ do klasyfikacji zmiennej nominalnej *siÅ‚a wiatru*, gdzie zbiorem wartoÅ›ci jest [*brak*, *sÅ‚aby*, *silny*, *bardzo silny*]?

---
Autorzy: *Piotr Kaczmarek* i *Jakub TomczyÅ„ski*
