# Lab 05 - Czyszczenie danych

Celem czyszczenia danych jest:
- wykrycie element贸w brakujcych i ich uzupenienie lub usunicie wierszy
- konwersja danych (np daty) i typ贸w nominalnych (w tym korekta bd贸w w nazwach element贸w np. pozna, Poznan, Pznan, Pozna)
- analiza rozkad贸w i usunicie element贸w odstajcych (outlier贸w) (Lab 06)
- normalizacja danych i normalizacja rozkadu (Lab 06)

W zadaniu spr贸buj odnie efekty wprowadzonych zmian do efektu dla zadania klasyfikacji. Do oceny zastosuj funkcj:
```Python
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error
def score_dataset(X_train, X_valid, y_train, y_valid):
    model = RandomForestRegressor(n_estimators=100, random_state=0)
    model.fit(X_train, y_train)
    preds = model.predict(X_valid)
    return mean_absolute_error(y_valid, preds)
```
Do oceny skutecznoci stosuj zawsze zbi贸r uczcy i tetsowy, tzn. wszelkie hipotezy, wyznaczanie statystyk (np. wartoci redniej, kwartyli) wyznaczaj wycznie dla zbioru uczcego, a nastpnie metod zastosuj dla zbioru testowego (bez zmiany wartoci wyznaczonych parametr贸w). Podzia na zbi贸r uczcy i testowego przeprowad藕 w proporcji 70/30%. Podzia na zbiory przeprowad藕 na pocztku i potem u偶ywaj tych zbior贸w dla wszystkich danych (rozwizanie to zawiera pewien bd metodyczny wynikajcy z wielokrotnego wykorzystania tego samego zbioru, zajmiemy si tym na Lab 07)
```Python
from sklearn.datasets import make_blobs
from sklearn.model_selection import train_test_split
train_df,test_df = train_test_split(df, test_size=0.7)
#czyszczenie danych
#train_df_cleaned = ...
#test_df_cleaned = ...
cols_x = train_df_cleaned.columns.select_dtypes(include=[np.number]).difference(['Price']) #wybiera tylko kolumny z wartosciami numerycznymi,za wyjtkiem kolumny z wartoci referencyjn
cols_y = 'Price'
print(score_dataset(train_df_cleaned[cols_x],test_df_cleaned[cols_x], train_df_cleaned[cols_y], test_df_cleaned[cols_y]))

```


**UWAGA** 
1. Funkcja ``score_dataset`` zwraca redni z wartoci bezwzgldnej bdu dla zbioru testowy, 
2. Do oceny skutecznoci stosujemy zbi贸r testowy, kt贸ry nie zosta u偶yty w procedurze uczenia i wyboru metody
3. Pamitaj jednak 偶e jednoznaczna interpretacja tego czy r贸偶nica midzy oboma podejciami jest istotna statystycznie wymaga rozszerzonej analizy, zajmiemy si tym na Lab07.
4. Por贸wnujc otrzymany wynik bdu spr贸buj okreli dlaczego nastpia zmiana, pamitaj przy tym 偶e podejcie zwizane z czyszczeniem danych zale偶y od danych.  

## Elementy brakujce
1. Wczytaj zbi贸r danych z [pliku](./_resources/lab_05/melb_data.csv) do zmiennej ``df``
2. Wyznaczanie liczb wartoci brakujcych (pustych) i przeanalizuj w jakich kolumnach wystpuj braki
```Python
missing_values_count = df.isnull().sum()
```
- spr贸buj okreli dla ka偶dej kolumny procent wystpowania wartoci brakujcych. Wywietl je w postaci tabeli gdzie indeksem jest nazwa kolumny a kolumnami procent brak贸w oraz cakowita liczba brak贸w (mo偶esz u偶y metody ``pd.concat``)
1. Podejcie 1: usunicie kolumn/wierszy zawierajcych przynajmniej 1 element pusty - przetestuj oba podejcia:
```Python
df_cleaned_rows = df_set.dropna()
df_cleaned_cols = df_set.dropna(axis=1)
```
- Zastan贸w si kt贸re z tych podej powinno by zastosowane jeli chcemy stworzy klasyfikator predykujcy ceny nieruchomoci?
- czy wiesz kt贸re wiersze zostay usunite - spr贸buj wyodrbni list ich indeks贸w?
- sprawd藕 dokumentacj [dropna](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html) i zobacz:
  -  w jaki spos贸b usun tylko wiersze z jeli wartoci puste s w kolumnie ``BuildingArea``, 
  -  ograniczajc liczb wierszy sprawd藕 ile zostanie wierszy jeli usunie si wiersze, kt贸re nie maj r贸wnoczenie wypenionego pola ``BuildingArea`` i  ``YearBuilt``
4. Podejcie 2: wypenienie pustych wartoci np. zerami lub wartoci kt贸ra poprzedza warto brakujc
``` Python
df_cleaned_zeros = df.fillna(0) # wypenia zerami
df_cleaned_bfill = df.fillna(method='bfill', axis=0).fillna(0) #wypenia wartoci poprzedzajc z kolumny, jeli to niemo偶liwe, wstawia 0
```
- Zastan贸w si kiedy takie podejcie mo偶e by stosowane, czy mo偶na je u偶y do klasyfikacji?, sprawd藕 w dokumentacji [fillna](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html) jakie s jeszcze mo偶liwoci wypenienia wypenienia?


5. Podejcie 3: podstawienie wartoci redniej/mediany/mody:
``` Python
from sklearn.impute import SimpleImputer
imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean') 
df_train_numeric = df_test.select_dtypes(include=[np.number]).copy()
df_test_numeric = df_test.select_dtypes(include=[np.number]).copy()#wyb贸r tylko kolumn przechowujacych liczby, nale偶y wykona kopi obiektu
df_train_numeric.loc[:] = imp_mean.fit_transform(df_train_numeric)#dopasowanie parametr贸w (rednich) i transformacja zbioru uczcego

df_test_numeric[:]  = imp_mean.transform(df_test_numeric) #zastosowanie modelu do transformacji zbioru testowego (bez wyznaczania parametr贸w)
```
- kiedy wypenianie wartoci ssiedni ma sens? Jeli stosujemy je do klasyfikacji to jak strategi przyj w odniesieniu do brakujcych wartoci referencyjnych (jest to warto, kt贸ra ma by predykowana przez klasyfikator) a jak w odniesieniu do brakujcych cech (warto/wartoci, kt贸re s wejciem klasyfikatora)?
- oce skuteczno klasyfikacji i por贸wnaj j z pozostaymi podejciami


## Konwersja danych
### konwersja daty
- konwersja danych z dat
- wyznaczanie interwa贸w
- wyznaczanie dnia tygodnia

### zmienne nominalne
- konwersja na zmienn nominaln
- czenie zmiennych nominalnych (usuwanie liter贸wek)
- zmienna porzdkowa -> konwersja na liczb
- zmienna nominalna -> zastosowanie encodera


---

####  Zadanie 1 



---
Autorzy: *Piotr Kaczmarek* i *Jakub Tomczyski*
